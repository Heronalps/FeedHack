{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from gensim.models.wrappers import FastText\n",
    "import gensim.models.fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Embedding Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load_fasttext_format('models/fasttext_skipgram_300_10.bin')\n",
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slowslow', 0.9461556673049927),\n",
       " ('slowww', 0.9150160551071167),\n",
       " ('sloww', 0.914790689945221),\n",
       " ('slowy', 0.9127247333526611),\n",
       " ('slowthe', 0.9061232209205627),\n",
       " ('slowwww', 0.9044946432113647),\n",
       " ('slowfast', 0.9032155275344849),\n",
       " ('slownot', 0.9016188383102417),\n",
       " ('slowno', 0.9011406898498535),\n",
       " ('slowand', 0.8921894431114197),\n",
       " ('slowmo', 0.8902242183685303),\n",
       " ('slowit', 0.8754894733428955),\n",
       " ('slowely', 0.8689318299293518),\n",
       " ('slowi', 0.8646904230117798),\n",
       " ('slowwwww', 0.8630250096321106),\n",
       " ('slowe', 0.8573843836784363),\n",
       " ('slowring', 0.8450390696525574),\n",
       " ('slowed', 0.8330438137054443),\n",
       " ('slower', 0.830303430557251),\n",
       " ('slowly', 0.8275282382965088),\n",
       " ('fastslow', 0.8224830627441406),\n",
       " ('slowest', 0.8189854621887207),\n",
       " ('laggyslow', 0.8144257068634033),\n",
       " ('slows', 0.8049894571304321),\n",
       " ('slugish', 0.8032950162887573)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('slow', topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedback_vector(text, wv):\n",
    "    tokens = text.split(\" \") \n",
    "    tokens = [token for token in tokens if token in wv.vocab] \n",
    "    vectors = np.array([wv[token] for token in tokens])\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"hello this is printer jfiena\"\n",
    "test_text_tokens = test_text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "fb_vec = get_feedback_vector(test_text, wv)\n",
    "print(fb_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.9 µs ± 6.62 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fb_vec = get_feedback_vector(test_text, wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Feedback Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pd.read_csv('data/stack_labeled_feedback.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "fb = fb[['ConformedFeedbackId', 'verbatim']]\n",
    "fb['verbatim'] = fb['verbatim'].apply(lambda text: str(text))\n",
    "fb['verbatim'] = fb['verbatim'].apply(lambda text: text.lower())\n",
    "fb['verbatim'] = fb['verbatim'].apply(lambda text: text.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(fb, wv):\n",
    "    fb['embeddings'] = fb['verbatim'].apply(lambda text: get_feedback_vector(text, wv))\n",
    "    fb[['x_{}'.format(i) for i in range(300)]] = fb['embeddings'].apply(pd.Series)\n",
    "    return fb_embeddings[['ConformedFeedbackId'] + ['x_{}'.format(i) for i in range(300)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100k_cbow_300_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model embeddings/embeddings_100k_cbow_300_10.csv\n",
      "100k_cbow_600_10\n",
      "Saved model embeddings/embeddings_100k_cbow_600_10.csv\n",
      "100k_cbow_600_5\n",
      "Saved model embeddings/embeddings_100k_cbow_600_5.csv\n",
      "100k_skipgram_300_10\n",
      "Saved model embeddings/embeddings_100k_skipgram_300_10.csv\n",
      "100k_skipgram_300_5\n",
      "Saved model embeddings/embeddings_100k_skipgram_300_5.csv\n",
      "100k_skipgram_600_10\n",
      "Saved model embeddings/embeddings_100k_skipgram_600_10.csv\n",
      "100k_skipgram_600_5\n",
      "Saved model embeddings/embeddings_100k_skipgram_600_5.csv\n",
      "cbow_300_10\n",
      "Saved model embeddings/embeddings_cbow_300_10.csv\n",
      "cbow_300_5\n",
      "Saved model embeddings/embeddings_cbow_300_5.csv\n",
      "cbow_600_10\n",
      "Saved model embeddings/embeddings_cbow_600_10.csv\n",
      "cbow_600_5\n",
      "Saved model embeddings/embeddings_cbow_600_5.csv\n",
      "skipgram_300_10\n",
      "Saved model embeddings/embeddings_skipgram_300_10.csv\n",
      "skipgram_300_5\n",
      "Saved model embeddings/embeddings_skipgram_300_5.csv\n",
      "skipgram_600_10\n",
      "Saved model embeddings/embeddings_skipgram_600_10.csv\n",
      "skipgram_600_5\n",
      "Saved model embeddings/embeddings_skipgram_600_5.csv\n"
     ]
    }
   ],
   "source": [
    "# get all the models\n",
    "model_files = [f for f in listdir('models/') if isfile(join('models/', f))]\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_name = model_file.split(\"_\")[1:]\n",
    "    model_name = \"_\".join(model_name)[:-4]\n",
    "    embeddings = get_embeddings(fb, wv)\n",
    "    embeddings_save_path = 'embeddings/embeddings_{}.csv'.format(model_name)\n",
    "    fb_embeddings.to_csv(embeddings_save_path, index=False)\n",
    "    print('Saved model {}'.format(embeddings_save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
