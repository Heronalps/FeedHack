{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FastText Models\n",
    "\n",
    "This notebook trains various character embeddings using FastText on Windows 10 UIF data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "from gensim.models.wrappers import FastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "    input             # training file path (required)\n",
    "    model             # unsupervised fasttext model {cbow, skipgram} [skipgram]\n",
    "    lr                # learning rate [0.05]\n",
    "    dim               # size of word vectors [100]\n",
    "    ws                # size of the context window [5]\n",
    "    epoch             # number of epochs [5]\n",
    "    minCount          # minimal number of word occurences [5]\n",
    "    minn              # min length of char ngram [3]\n",
    "    maxn              # max length of char ngram [6]\n",
    "    neg               # number of negatives sampled [5]\n",
    "    wordNgrams        # max length of word ngram [1]\n",
    "    loss              # loss function {ns, hs, softmax, ova} [ns]\n",
    "    bucket            # number of buckets [2000000]\n",
    "    thread            # number of threads [number of cpus]\n",
    "    lrUpdateRate      # change the rate of updates for the learning rate [100]\n",
    "    t                 # sampling threshold [0.0001]\n",
    "    verbose           # verbose [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameter combinations\n",
    "params = {\n",
    "    \"model\":  [\"cbow\", \"skipgram\"],\n",
    "    \"lr\": [0.0025],\n",
    "    \"dim\": [300, 600],\n",
    "    \"ws\": [5, 10],\n",
    "    \"epoch\": [5],\n",
    "    \"minCount\": [10],\n",
    "    \"minn\": [5],\n",
    "    \"maxn\": [5],\n",
    "    \"neg\": [5],\n",
    "    \"thread\": [6]\n",
    "}\n",
    "\n",
    "combinations = product(*(params[Name] for Name in params.keys()))\n",
    "param_combs = [dict(zip(params.keys(),v)) for v in product(*params.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train_fasttext(params, input_data):\n",
    "    print('\\nTraining FastText on {}...'.format(input_data))\n",
    "    print('Training parameters: \\n{}'.format(str(params)))\n",
    "    s_time = time.time()\n",
    "    ft_model = fasttext.train_unsupervised(input_data, \n",
    "                                           dim=params['dim'],\n",
    "                                           model=params['model'],\n",
    "                                           epoch=params['epoch'],\n",
    "                                           lr=params['lr'],\n",
    "                                           maxn=params['maxn'],\n",
    "                                           minCount=params['minCount'],\n",
    "                                           minn=params['minn'],\n",
    "                                           neg=params['neg'],\n",
    "                                           thread=params['thread'],\n",
    "                                           ws=params['ws'])\n",
    "    e_time = time.time()\n",
    "    print('Training complete. Elapsed time: {0:.2f}s'.format(e_time - s_time))\n",
    "    return ft_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 300, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'cbow', 'epoch': 5, 'ws': 5, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 623.07s\n",
      "Model saved at models/fasttext_cbow_300_5.bin\n",
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 300, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'cbow', 'epoch': 5, 'ws': 10, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 802.58s\n",
      "Model saved at models/fasttext_cbow_300_10.bin\n",
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 300, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'skipgram', 'epoch': 5, 'ws': 5, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 1748.02s\n",
      "Model saved at models/fasttext_skipgram_300_5.binModel saved at models/fasttext_cbow_600_5.bin\n",
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 600, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'cbow', 'epoch': 5, 'ws': 10, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 1394.07s\n",
      "Model saved at models/fasttext_cbow_600_10.bin\n",
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 600, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'skipgram', 'epoch': 5, 'ws': 5, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 3215.24s\n",
      "Model saved at models/fasttext_skipgram_600_5.bin\n",
      "\n",
      "Training FastText on data/uif_data_clean.tsv...\n",
      "Training parameters: \n",
      "{'dim': 600, 'neg': 5, 'lr': 0.0025, 'maxn': 5, 'minCount': 10, 'model': 'skipgram', 'epoch': 5, 'ws': 10, 'thread': 6, 'minn': 5}\n",
      "Training complete. Elapsed time: 5046.98s\n",
      "Model saved at models/fasttext_skipgram_600_10.bin\n"
     ]
    }
   ],
   "source": [
    "# train fasttext\n",
    "input_data = 'data/uif_data_clean.tsv'\n",
    "\n",
    "for params in param_combs:\n",
    "    model = train_fasttext(params, input_data)\n",
    "    save_path = 'models/fasttext_{}_{}_{}.bin'.format(params['model'], params['dim'], params['ws'])\n",
    "    model.save_model(save_path)\n",
    "    print('Model saved at {}'.format(save_path)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
